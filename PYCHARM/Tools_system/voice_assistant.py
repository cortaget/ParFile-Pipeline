# voice_assistant.py
import json
import requests
from core.tool_decorator import registry

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –≤—Å–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
from tools import calculator_tool, time_tool

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ Ollama
LLM_URL = "http://127.0.0.1:11434/api/chat"
LLM_MODEL = "gemma3:4b"

chat_history = []


def query_llm_with_tools(user_input: str) -> str:
    """–ó–∞–ø—Ä–æ—Å –∫ LLM —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤"""

    # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    messages = chat_history + [{"role": "user", "content": user_input}]

    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
    tools = registry.get_tool_definitions()

    payload = {
        "model": LLM_MODEL,
        "messages": messages,
        "tools": tools,
        "stream": False
    }

    try:
        response = requests.post(LLM_URL, json=payload)

        if response.status_code != 200:
            return f"–û—à–∏–±–∫–∞: {response.status_code}"

        result = response.json()
        message = result.get("message", {})

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Ö–æ—á–µ—Ç –ª–∏ –º–æ–¥–µ–ª—å –≤—ã–∑–≤–∞—Ç—å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç
        if "tool_calls" in message and message["tool_calls"]:
            print("üîß –ú–æ–¥–µ–ª—å –≤—ã–∑—ã–≤–∞–µ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç...")

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—ã–∑–æ–≤—ã –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
            tool_results = []
            for tool_call in message["tool_calls"]:
                function = tool_call.get("function", {})
                tool_name = function.get("name")
                arguments = function.get("arguments", {})

                print(f"   ‚Üí {tool_name}({arguments})")

                # –í—ã–∑—ã–≤–∞–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç
                result = registry.call_tool(tool_name, arguments)
                tool_results.append({
                    "role": "tool",
                    "content": json.dumps(result, ensure_ascii=False)
                })

            # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç
            messages.append(message)
            messages.extend(tool_results)

            # –ü–æ–≤—Ç–æ—Ä–Ω—ã–π –∑–∞–ø—Ä–æ—Å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
            payload["messages"] = messages
            payload.pop("tools")  # –£–±–∏—Ä–∞–µ–º tools –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞

            final_response = requests.post(LLM_URL, json=payload)
            final_message = final_response.json().get("message", {})
            final_content = final_message.get("content", "")

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
            chat_history.append({"role": "user", "content": user_input})
            chat_history.append({"role": "assistant", "content": final_content})

            return final_content
        else:
            # –û–±—ã—á–Ω—ã–π –æ—Ç–≤–µ—Ç –±–µ–∑ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
            content = message.get("content", "")
            chat_history.append({"role": "user", "content": user_input})
            chat_history.append({"role": "assistant", "content": content})
            return content

    except Exception as e:
        return f"–û—à–∏–±–∫–∞: {str(e)}"
